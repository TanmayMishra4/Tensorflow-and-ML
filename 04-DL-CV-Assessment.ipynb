{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>\n",
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 4us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 14s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cd8a25150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train/255.0\n",
    "x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,28,28,1)\n",
    "x_test=x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.9843 - accuracy: 0.8408 - val_loss: 0.4104 - val_accuracy: 0.8518\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3712 - accuracy: 0.8723 - val_loss: 0.4408 - val_accuracy: 0.8604\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3551 - accuracy: 0.8779 - val_loss: 0.4325 - val_accuracy: 0.8483\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3495 - accuracy: 0.8817 - val_loss: 0.4231 - val_accuracy: 0.8633\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3464 - accuracy: 0.8834 - val_loss: 0.5062 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3455 - accuracy: 0.8837 - val_loss: 0.4241 - val_accuracy: 0.8612\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3461 - accuracy: 0.8873 - val_loss: 0.4590 - val_accuracy: 0.8694\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3478 - accuracy: 0.8851 - val_loss: 0.4746 - val_accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3484 - accuracy: 0.8841 - val_loss: 0.4801 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.3567 - accuracy: 0.8819 - val_loss: 0.4937 - val_accuracy: 0.8463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cb93b0090>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_cat_train,epochs=10,use_multiprocessing=True,validation_data=(x_test,y_cat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5788074731826782, 0.7918000221252441]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test,y=y_cat_test,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-cef9a1547054>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
